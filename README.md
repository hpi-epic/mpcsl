# Master Project: Causal Inference Pipeline

This repository contains the backend of a Causal Inference pipeline build during the Master Project 2018/19 at the HPI chair for Enterprise Platform and Integration Concepts. The pipeline currently includes the following features, which are all accessible via a REST-api:

- Store causal inference ready datasets into our backend
- Set up causal inference experiments for the pcalg algorithm in R with different hyperparameter settings and dataset choice
- Run the experiments as jobs directly in our backend
- Manage all currently running jobs on the backend
- Deliver the results and metainformation of past experiments 

The following features are currently under active development and will be added in the following months:

- Receive additional metainformation from past experiments
- Add the choice of additional causal inference algorithms
- Give people the opportunity to extend the pipeline with their own algorithms 
- Integrate prior knowledge into the algorithms
- Add additional steps to pre-process datasets

The following image shows the holistic architecture as a FMC diagram:

<img src="https://user-images.githubusercontent.com/8962207/50157097-d2869800-02d0-11e9-9c15-299442846712.png" width="600" title="FMC Architecture Diagram">

Additionally, the data model can be seen as ER diagram:

<img src="https://user-images.githubusercontent.com/8962207/50157111-e03c1d80-02d0-11e9-80a9-96d301355201.png" width="600" title="ER Datamodel Diagram">

## Setup

### Docker

The full backend setup is done using a docker container that means that you will require docker to be running for a local execution. Afterwards, you can clone the repository using:

```
git clone git@github.com:danthe96/mpci.git
```

Then we can move into the repository to build the backend using:

```
cp confdefault/backend.env conf/backend.env
cp confdefault/algorithms.json conf/algorithms.json
docker-compose build
```

To initialize the database we have to run the following command:
```
docker-compose run backend flask db upgrade
```
Finally, we can start our backend with the default configuration using:
```
docker-compose up
```

### Setup with user interface

As the user interface files are stored in a different repository (https://github.com/threxx/mpci-frontend),
you have to clone the repo using:

```
git clone --recurse-submodules git@github.com:danthe96/mpci.git
```

If you already cloned the repo without submodules, they have to be initialized using git submodule:

```
git submodule update --remote --init 
```

When the UI files are present, the full setup can be build using:
```
cp confdefault/backend.env conf/backend.env
cp confdefault/algorithms.json conf/algorithms.json
docker-compose -f docker-compose-nginx.yml build
```

To initialize the database we have to run the following command:
```
docker-compose -f docker-compose-nginx.yml run backend flask db upgrade
```

Finally, we can start our frontend and backend with the default configuration using:
```
docker-compose -f docker-compose-nginx.yml up
```
This will deploy the backend with an additional nginx server, that is used
to serve static files and provide the backend functionality by connecting to uWSGI.
The transpilation of the UI files will be done during build. If the UI files change,
it is necessary to rebuild the frontend container.

### Seeding the database
The files include a small seed-script that generates a randomized dataset.
The seed script can be run using:

```
docker-compose run backend python seed.py
```

If you are running the UI build, you have to include the -nginx.yml compose file.

### Migrating the database


A clear database is needed to launch. This is especially important,
as the tests create all tables without using the migration system.
To get a clear database run:
```
docker-compose down
```
This command will clear all volumes, including the database.

Otherwise you can run the following SQL command using the DB ui or a postgres 
admin interface of your choice.
```
DROP SCHEMA public CASCADE; CREATE SCHEMA public 
```

When the models have been changed, make sure your database is up to date by using:
```
# (optional) Check first if configuration files need to be updated
diff confdefault/backend.env conf/backend.env
diff confdefault/algorithms.json conf/algorithms.json
docker-compose run backend flask db upgrade
```

Afterwards, you can auto-create an migration by using:
```
docker-compose run backend flask db migrate -m "migration message"
```
If alembic does not detect your changes correctly, you can manually create
an empty migration by using:
```
dokcer-compose run backend flask db revision -m "migration message"
```

You can then either manipulate the autogenerated commands or insert new commands
in the new migration file.

When you are done, re-run upgrade to apply your changes to your local instance.

Alembic is used for the migration system. Alembic does not auto-detect the following changes correctly:
- Table and column renames (are detected as deleted and added with another name)
- Column type changes (are not detected at all, remember to add conversion function when adding them manually)

This list might not be complete, be sure to check the Alembic documentation for further information.

## Endpoint Documentation

A Swagger documentation of our REST endpoints is available using
http://localhost:5000/static/swagger/index.html
given default host and port settings.
